{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 885,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import re\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.corpus import stopwords\n",
    "from autocorrect import spell\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "from collections import Counter\n",
    "\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "\n",
    "## Modeling \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.sentiment.sentiment_analyzer import SentimentAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 865,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['offenseval-annotation.txt',\n",
       " 'offenseval-training-v1.tsv',\n",
       " 'readme-trainingset-v1.txt']"
      ]
     },
     "execution_count": 865,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(os.getcwd()+\"\\\\training-v1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Reading in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 954,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = []\n",
    "train_df = pd.DataFrame()\n",
    "\n",
    "with open('.\\\\training-v1\\\\offenseval-training-v1.tsv','r', encoding = 'utf-8') as in_file:\n",
    "    #train_data = [line.strip().split('\\t') for line in in_file]\n",
    "    \n",
    "    for line in in_file:\n",
    "        train_df = pd.concat([train_df,pd.DataFrame([line.strip().split('\\t')])], axis = 0)\n",
    "        \n",
    "train_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Analyzing the data and response variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 955,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setting the first row as the column headers\n",
    "train_df.columns = train_df.iloc[0,:].values\n",
    "train_df = train_df.iloc[1:,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 956,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>subtask_a</th>\n",
       "      <th>subtask_b</th>\n",
       "      <th>subtask_c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>86426</td>\n",
       "      <td>@USER She should ask a few native Americans wh...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>UNT</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>90194</td>\n",
       "      <td>@USER @USER Go home you’re drunk!!! @USER #MAG...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>IND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>16820</td>\n",
       "      <td>Amazon is investigating Chinese employees who ...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>62688</td>\n",
       "      <td>\"@USER Someone should'veTaken\"\" this piece of ...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>UNT</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>43605</td>\n",
       "      <td>@USER @USER Obama wanted liberals &amp;amp; illega...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0     id                                              tweet subtask_a  \\\n",
       "1  0  86426  @USER She should ask a few native Americans wh...       OFF   \n",
       "2  0  90194  @USER @USER Go home you’re drunk!!! @USER #MAG...       OFF   \n",
       "3  0  16820  Amazon is investigating Chinese employees who ...       NOT   \n",
       "4  0  62688  \"@USER Someone should'veTaken\"\" this piece of ...       OFF   \n",
       "5  0  43605  @USER @USER Obama wanted liberals &amp; illega...       NOT   \n",
       "\n",
       "  subtask_b subtask_c  \n",
       "1       UNT      NULL  \n",
       "2       TIN       IND  \n",
       "3      NULL      NULL  \n",
       "4       UNT      NULL  \n",
       "5      NULL      NULL  "
      ]
     },
     "execution_count": 956,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 957,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13240, 6)"
      ]
     },
     "execution_count": 957,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distribution of each of the sub-tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 958,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NOT    8840\n",
       "OFF    4400\n",
       "Name: subtask_a, dtype: int64"
      ]
     },
     "execution_count": 958,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.subtask_a.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 959,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NULL    8840\n",
       "TIN     3876\n",
       "UNT      524\n",
       "Name: subtask_b, dtype: int64"
      ]
     },
     "execution_count": 959,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.subtask_b.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 960,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NULL    9364\n",
       "IND     2407\n",
       "GRP     1074\n",
       "OTH      395\n",
       "Name: subtask_c, dtype: int64"
      ]
     },
     "execution_count": 960,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.subtask_c.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 961,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#train_df.tweet.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 962,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>subtask_a</th>\n",
       "      <th>subtask_b</th>\n",
       "      <th>subtask_c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1270</th>\n",
       "      <td>0</td>\n",
       "      <td>45643</td>\n",
       "      <td>@USER Looks Like The Jokes On Liberals Again. ...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4073</th>\n",
       "      <td>0</td>\n",
       "      <td>22953</td>\n",
       "      <td>@USER Looks Like The Jokes On Liberals Again. ...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8333</th>\n",
       "      <td>0</td>\n",
       "      <td>60513</td>\n",
       "      <td>@USER Looks Like The Jokes On Liberals Again. ...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>GRP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10460</th>\n",
       "      <td>0</td>\n",
       "      <td>66322</td>\n",
       "      <td>@USER Looks Like The Jokes On Liberals Again. ...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10624</th>\n",
       "      <td>0</td>\n",
       "      <td>38491</td>\n",
       "      <td>@USER Looks Like The Jokes On Liberals Again. ...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11304</th>\n",
       "      <td>0</td>\n",
       "      <td>73520</td>\n",
       "      <td>@USER Looks Like The Jokes On Liberals Again. ...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0     id                                              tweet subtask_a  \\\n",
       "1270   0  45643  @USER Looks Like The Jokes On Liberals Again. ...       NOT   \n",
       "4073   0  22953  @USER Looks Like The Jokes On Liberals Again. ...       NOT   \n",
       "8333   0  60513  @USER Looks Like The Jokes On Liberals Again. ...       OFF   \n",
       "10460  0  66322  @USER Looks Like The Jokes On Liberals Again. ...       NOT   \n",
       "10624  0  38491  @USER Looks Like The Jokes On Liberals Again. ...       NOT   \n",
       "11304  0  73520  @USER Looks Like The Jokes On Liberals Again. ...       NOT   \n",
       "\n",
       "      subtask_b subtask_c  \n",
       "1270       NULL      NULL  \n",
       "4073       NULL      NULL  \n",
       "8333        TIN       GRP  \n",
       "10460      NULL      NULL  \n",
       "10624      NULL      NULL  \n",
       "11304      NULL      NULL  "
      ]
     },
     "execution_count": 962,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[train_df.tweet == '@USER Looks Like The Jokes On Liberals Again.  #FortTrump #Poland #BoomingEconomy URL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 963,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>subtask_a</th>\n",
       "      <th>subtask_b</th>\n",
       "      <th>subtask_c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5166</th>\n",
       "      <td>0</td>\n",
       "      <td>81140</td>\n",
       "      <td>@USER An obvious last minute liberal ploy to d...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5307</th>\n",
       "      <td>0</td>\n",
       "      <td>46503</td>\n",
       "      <td>@USER An obvious last minute liberal ploy to d...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     id                                              tweet subtask_a  \\\n",
       "5166  0  81140  @USER An obvious last minute liberal ploy to d...       NOT   \n",
       "5307  0  46503  @USER An obvious last minute liberal ploy to d...       NOT   \n",
       "\n",
       "     subtask_b subtask_c  \n",
       "5166      NULL      NULL  \n",
       "5307      NULL      NULL  "
      ]
     },
     "execution_count": 963,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[train_df.tweet == \"@USER An obvious last minute liberal ploy to delay confirmation. More dirty tricks since the liberals lost the previous election.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 964,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>subtask_a</th>\n",
       "      <th>subtask_b</th>\n",
       "      <th>subtask_c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2144</th>\n",
       "      <td>0</td>\n",
       "      <td>14617</td>\n",
       "      <td>@USER @USER @USER @USER @USER @USER @USER @USE...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2724</th>\n",
       "      <td>0</td>\n",
       "      <td>16759</td>\n",
       "      <td>@USER @USER @USER @USER @USER @USER @USER @USE...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4223</th>\n",
       "      <td>0</td>\n",
       "      <td>15862</td>\n",
       "      <td>@USER @USER @USER @USER @USER @USER @USER @USE...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     id                                              tweet subtask_a  \\\n",
       "2144  0  14617  @USER @USER @USER @USER @USER @USER @USER @USE...       NOT   \n",
       "2724  0  16759  @USER @USER @USER @USER @USER @USER @USER @USE...       NOT   \n",
       "4223  0  15862  @USER @USER @USER @USER @USER @USER @USER @USE...       NOT   \n",
       "\n",
       "     subtask_b subtask_c  \n",
       "2144      NULL      NULL  \n",
       "2724      NULL      NULL  \n",
       "4223      NULL      NULL  "
      ]
     },
     "execution_count": 964,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[train_df.tweet ==  \"@USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER Following all #Maga patriots please follow back 👍  #LionsDen 🦁  #MAGA2KAG 🇺🇸\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 965,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_df.tweet = train_df.tweet.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1130,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Spelling correction\n",
    "def spell_correct(text):\n",
    "    ### Removes letter repitition and corrects spellings\n",
    "    pattern = re.compile(r\"(.)\\1{2,}\")\n",
    "    return spell(pattern.sub(r\"\\1\\1\", text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1136,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Correct spellings\n",
    "# clean_words = train_df.tweet.apply(lambda x: ' '.join([spell_correct(words) for words in x.split(\" \")]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Sentiment Polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 878,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_polarity_values = train_df.tweet.apply(lambda x: SentimentIntensityAnalyzer().polarity_scores(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 879,
   "metadata": {},
   "outputs": [],
   "source": [
    "polarity_array = []\n",
    "\n",
    "for each in sentiment_polarity_values:\n",
    "    temp_polarity_array = list(each.values())\n",
    "    polarity_array.append(temp_polarity_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Word2Vec Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stopword collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1031,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Getting stopwords\n",
    "stop_words_list = stopwords.words('english')\n",
    "tweet_tokens = train_df.tweet.apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1032,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Combining all the tokenized words\n",
    "words = ' '.join(words for sent in tweet_tokens.values for words in sent )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1033,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count = Counter(words.split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1034,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Selecting words with frequency 1\n",
    "less_freq_words = [word for (word,count) in word_count.most_common()[-16200:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1035,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('@', 33437),\n",
       " ('USER', 33412),\n",
       " ('.', 14360),\n",
       " ('the', 8071),\n",
       " ('is', 6392),\n",
       " ('to', 6170),\n",
       " (\"''\", 5565),\n",
       " ('#', 5399),\n",
       " ('a', 5103),\n",
       " ('!', 5099),\n",
       " ('and', 4588),\n",
       " ('you', 4063),\n",
       " ('of', 3731),\n",
       " ('are', 3465),\n",
       " ('I', 3440),\n",
       " ('?', 3016),\n",
       " ('that', 2629),\n",
       " ('in', 2575),\n",
       " ('’', 2574),\n",
       " ('for', 2382),\n",
       " ('URL', 2058),\n",
       " ('it', 2026),\n",
       " ('he', 1880),\n",
       " ('...', 1806),\n",
       " ('on', 1648),\n",
       " ('she', 1559),\n",
       " ('not', 1466),\n",
       " ('with', 1450),\n",
       " ('have', 1415),\n",
       " (\"'s\", 1393),\n",
       " ('be', 1373),\n",
       " ('this', 1372),\n",
       " ('``', 1347),\n",
       " (\"n't\", 1289),\n",
       " ('You', 1245),\n",
       " ('do', 1239),\n",
       " (',', 1235),\n",
       " ('they', 1221),\n",
       " ('He', 1159),\n",
       " ('gun', 1144),\n",
       " ('control', 1114),\n",
       " ('all', 1055),\n",
       " ('your', 1047),\n",
       " ('like', 1025),\n",
       " ('s', 995),\n",
       " ('was', 984),\n",
       " ('about', 982),\n",
       " ('as', 976),\n",
       " ('t', 958),\n",
       " ('so', 945),\n",
       " ('her', 933),\n",
       " ('She', 922),\n",
       " ('will', 898),\n",
       " ('MAGA', 883),\n",
       " (';', 883),\n",
       " ('liberals', 866),\n",
       " ('who', 853),\n",
       " ('The', 836),\n",
       " ('what', 828),\n",
       " ('just', 827),\n",
       " ('people', 824),\n",
       " ('but', 786),\n",
       " ('&', 784),\n",
       " ('from', 730),\n",
       " ('has', 721),\n",
       " ('his', 720),\n",
       " ('at', 706),\n",
       " ('by', 704),\n",
       " ('amp', 677),\n",
       " ('we', 676),\n",
       " ('can', 672),\n",
       " ('an', 667),\n",
       " ('up', 665),\n",
       " ('out', 659),\n",
       " ('or', 654),\n",
       " ('their', 648),\n",
       " ('if', 642),\n",
       " ('It', 625),\n",
       " ('my', 618),\n",
       " ('know', 617),\n",
       " ('me', 606),\n",
       " ('Antifa', 603),\n",
       " ('get', 576),\n",
       " ('conservatives', 572),\n",
       " ('one', 567),\n",
       " ('no', 562),\n",
       " ('him', 561),\n",
       " ('more', 542),\n",
       " (':', 540),\n",
       " ('them', 539),\n",
       " ('would', 537),\n",
       " ('how', 537),\n",
       " ('when', 534),\n",
       " ('think', 532),\n",
       " ('Trump', 523),\n",
       " ('Liberals', 501),\n",
       " ('should', 487),\n",
       " ('And', 482),\n",
       " (')', 480),\n",
       " ('because', 470),\n",
       " ('(', 432),\n",
       " ('This', 424),\n",
       " ('our', 414),\n",
       " ('now', 412),\n",
       " ('They', 411),\n",
       " ('We', 410),\n",
       " ('right', 408),\n",
       " ('there', 408),\n",
       " ('-', 378),\n",
       " ('want', 373),\n",
       " ('That', 369),\n",
       " ('only', 366),\n",
       " ('Conservatives', 357),\n",
       " ('did', 357),\n",
       " ('why', 357),\n",
       " ('than', 354),\n",
       " ('time', 346),\n",
       " ('need', 345),\n",
       " ('going', 345),\n",
       " ('been', 335),\n",
       " ('being', 333),\n",
       " ('good', 332),\n",
       " ('antifa', 327),\n",
       " ('does', 324),\n",
       " ('see', 322),\n",
       " ('”', 321),\n",
       " ('say', 320),\n",
       " ('shit', 319),\n",
       " ('us', 316),\n",
       " ('What', 315),\n",
       " ('“', 313),\n",
       " ('i', 308),\n",
       " ('were', 306),\n",
       " ('If', 304),\n",
       " ('never', 300),\n",
       " ('don', 299),\n",
       " ('go', 298),\n",
       " ('way', 296),\n",
       " ('any', 290),\n",
       " ('back', 290),\n",
       " ('make', 289),\n",
       " ('A', 281),\n",
       " ('So', 278),\n",
       " ('even', 277),\n",
       " ('too', 275),\n",
       " ('other', 273),\n",
       " ('some', 273),\n",
       " ('But', 273),\n",
       " ('still', 273),\n",
       " ('then', 273),\n",
       " ('really', 271),\n",
       " ('had', 271),\n",
       " ('over', 268),\n",
       " ('these', 267),\n",
       " (\"'re\", 267),\n",
       " ('much', 263),\n",
       " ('love', 261),\n",
       " ('Why', 248),\n",
       " ('believe', 241),\n",
       " (\"'m\", 239),\n",
       " ('left', 238),\n",
       " ('better', 235),\n",
       " ('said', 232),\n",
       " ('No', 228),\n",
       " ('man', 228),\n",
       " ('against', 222),\n",
       " ('take', 218),\n",
       " ('most', 217),\n",
       " ('Kavanaugh', 215),\n",
       " ('down', 215),\n",
       " ('country', 214),\n",
       " ('could', 211),\n",
       " ('How', 211),\n",
       " ('into', 209),\n",
       " ('ANTIFA', 209),\n",
       " ('doing', 205),\n",
       " ('those', 205),\n",
       " ('also', 201),\n",
       " ('thing', 201),\n",
       " ('very', 201),\n",
       " ('years', 200),\n",
       " ('many', 198),\n",
       " ('m', 196),\n",
       " ('here', 196),\n",
       " ('Gun', 195),\n",
       " ('Do', 189),\n",
       " ('well', 188),\n",
       " ('support', 186),\n",
       " ('Democrats', 186),\n",
       " ('vote', 186),\n",
       " ('am', 185),\n",
       " ('trying', 185),\n",
       " ('2', 183),\n",
       " ('same', 181),\n",
       " ('off', 181),\n",
       " ('sure', 181),\n",
       " ('got', 180),\n",
       " ('money', 179),\n",
       " ('laws', 178),\n",
       " ('party', 177)]"
      ]
     },
     "execution_count": 1035,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_count.most_common(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1036,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_freq_words = [word for (word,count) in word_count.most_common(100)]\n",
    "words_to_keep = ['gun','control','MAGA','liberals','Antifa','conservatives','Trump','Liberals','amp','people','control','god',\n",
    "                'right','Conservatives','good','antifa','don','love','better','most','Kavanaugh','ANTIFA','Gun','support',\n",
    "                'america','thank','lol','nothing','Democrats','vote','trying','money','laws','party','very','country','down','No','man','president']\n",
    "words_to_keep = [each.lower() for each in words_to_keep]\n",
    "_ = [high_freq_words.remove(each) for each in set(words_to_keep) if each in high_freq_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1037,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words_list.extend(less_freq_words)\n",
    "stop_words_list.extend(high_freq_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing stopwords from tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 973,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_tokens_clean = tweet_tokens.apply(lambda x: [words for words in x if words not in stop_words_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 974,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_tokens_clean_list = [list(np.where(len(each) > 0,each,['UNK'])) for each in tweet_tokens_clean]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating Word2Vec models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 895,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "from gensim.test.utils import datapath, get_tmpfile\n",
    "tmp_file = get_tmpfile(\"glove.twitter.27B.200d.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 907,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepend_slow(infile, outfile, line):\n",
    "\t\"\"\"\n",
    "\tSlower way to prepend the line by re-creating the inputfile.\n",
    "\t\"\"\"\n",
    "\twith open(infile, 'r',encoding = 'utf8') as fin:\n",
    "\t\twith open(outfile, 'w',encoding = 'utf8') as fout:\n",
    "\t\t\tfout.write(line + \"\\n\")\n",
    "\t\t\tfor line in fin:\n",
    "\t\t\t\tfout.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 908,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepend_slow(\"glove.twitter.27B.200d.txt\",\"glove.twitter.27B.200d_out.txt\",\"400000 200\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 909,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KeyedVectors.load_word2vec_format(\"glove.twitter.27B.200d_out.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = Word2Vec(tweet_tokens_clean_list, size = 200, window=5, min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 917,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.vocab.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 920,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_array = np.random.rand(100)\n",
    "embedding_list = []\n",
    "for each in tweet_tokens_clean_list:\n",
    "    each_filter = [words for words in each if words in model.vocab.keys()]\n",
    "    \n",
    "    if(len(each_filter) == 0):\n",
    "        embedding_list.append(list(random_array))\n",
    "    else:\n",
    "        embedding_list.append(list(np.mean(model[each_filter],axis = 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 928,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embeddings_df = pd.DataFrame(embedding_list)\n",
    "word_embeddings_df = word_embeddings_df.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 Number of Hashtags and Number of User count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 949,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_token_space = train_df.tweet.apply(lambda x: x.split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 950,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_counts = tweet_token_space.apply(lambda x:  len( [each for each in x if each.startswith('@')])).values\n",
    "hast_tag_counts = tweet_token_space.apply(lambda x:  len( [each for each in x if each.startswith('#')])).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4 Character n-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2ngrams(text, n=3, exact=True):\n",
    "    \"\"\" Convert text into character ngrams. \"\"\"\n",
    "    return [\"\".join(j) for j in zip(*[text[i:] for i in range(n)])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_3_gram = train_df.tweet.apply(word2ngrams,n = 3)\n",
    "char_4_gram = train_df.tweet.apply(word2ngrams,n = 4)\n",
    "char_5_gram = train_df.tweet.apply(word2ngrams,n = 5)\n",
    "char_6_gram = train_df.tweet.apply(word2ngrams,n = 6)\n",
    "char_7_gram = train_df.tweet.apply(word2ngrams,n = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_3_gram_dict = {}\n",
    "char_4_gram_dict = {}\n",
    "char_5_gram_dict = {}\n",
    "char_6_gram_dict = {}\n",
    "char_7_gram_dict = {}\n",
    "\n",
    "for row_num, text in enumerate(train_df.tweet):\n",
    "    char_3_gram_dict[text] = char_3_gram.values[row_num]\n",
    "    char_4_gram_dict[text] = char_4_gram.values[row_num]\n",
    "    char_5_gram_dict[text] = char_5_gram.values[row_num]\n",
    "    char_6_gram_dict[text] = char_6_gram.values[row_num]\n",
    "    char_7_gram_dict[text] = char_7_gram.values[row_num]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5 Dictionary of cuss words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuss_words_df = pd.DataFrame()\n",
    "\n",
    "for alphas in list(string.ascii_lowercase):\n",
    "    #print(alphas)\n",
    "    url = \"https://www.noswearing.com//dictionary//\"+alphas\n",
    "    XML = requests.get(url)\n",
    "\n",
    "    tree = html.fromstring(XML.content)\n",
    "    \n",
    "    td_files = tree.xpath(\"//center\")[4].getchildren()[0].getchildren()[1].getchildren()[0].getchildren()[0]\n",
    "\n",
    "    for tags in td_files.getchildren():\n",
    "        if(tags.text != None):\n",
    "\n",
    "            #print(tags.text)\n",
    "            #print(tags.tail)\n",
    "            test = pd.DataFrame({'Cuss_word':[tags.text.strip()],'Meaning':[tags.tail.replace(\"-\",\"\").strip()]})\n",
    "            cuss_words_df = pd.concat([cuss_words_df,test],axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuss_words_df.reset_index(inplace=True,drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1084,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cuss = list(set(cuss_words_df.Cuss_word.values)) + list(set(cuss_words_df.Meaning.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arvra\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2957: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "### Presence of cuss word\n",
    "cuss_total = train_df.tweet.apply(lambda x: len([words for words in word_tokenize(x) if words.lower() in all_cuss]))\n",
    "\n",
    "## Position of cuss word\n",
    "cuss_position = train_df.tweet.apply(lambda x: np.mean([pos for pos,words in enumerate(word_tokenize(x)) if words.lower() in all_cuss]))\n",
    "cuss_position = cuss_position.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.6 POS Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tweet_pos = train_df.tweet.apply(lambda x: (x.split(\" \")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 951,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/35867484/pass-tokens-to-countvectorizer\n",
    "stop_words_list.append('user')\n",
    "stop_words_list.append('url')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 984,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_counts_char_n_gram = CountVectorizer(tokenizer=lambda key: char_4_gram_dict[key],\n",
    "                                         preprocessor= lambda x:x, lowercase=False,stop_words = stop_words_list)\n",
    "bow_data_char_n_gram = bow_counts_char_n_gram.fit_transform(train_df.tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1063,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_counts = CountVectorizer(tokenizer= word_tokenize, stop_words = stop_words_list,ngram_range=(1,2))\n",
    "bow_data = bow_counts.fit_transform(train_df.tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tf Idf Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_counts_char_gram = TfidfVectorizer(tokenizer=lambda key: char_5_gram_dict[key], preprocessor= lambda x:x, lowercase=False)\n",
    "tfidf_data_char_gram = tfidf_counts_char_gram.fit_transform(train_df.tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_counts = TfidfVectorizer(tokenizer=word_tokenize, stop_words = stop_words_list,ngram_range=(1,4))\n",
    "tfidf_data = tfidf_counts.fit_transform(train_df.tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [],
   "source": [
    "#senti_analyser = SentimentAnalyzer()\n",
    "#senti_analyser.all_words(train_df.tweet.values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 937,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tfidf_data2 = np.concatenate((list(user_counts),embedding_list),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1140,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Input data\n",
    "#tfidf_data_char_gram\n",
    "X = sp.sparse.hstack((bow_data,pd.DataFrame([user_counts,hast_tag_counts]).T.values,\n",
    "                      word_embeddings_df.values,pd.DataFrame([cuss_total,cuss_position]).T.values,\n",
    "                     pd.DataFrame(polarity_array).values ) ,format='csr')\n",
    "\n",
    "### Input Column names\n",
    "X_columns=bow_counts.get_feature_names()+['user_counts','hash_tag_counts'] + list(word_embeddings_df.columns.values) + \\\n",
    "                                        ['Cuss_word','Cuss_position'] + ['Polarity1','Polarity2','Polarity3','Polarity4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1141,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_bow, X_test_bow, y_train_bow, y_test_bow =  \\\n",
    "                            train_test_split(X,train_df.subtask_a,test_size = 0.2,random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1142,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_char, X_test_char, y_train_char, y_test_char = \\\n",
    "                train_test_split(bow_data_char_n_gram,train_df.subtask_a,test_size = 0.2,random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Logistic Regression Model - BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75 :  0.7722846821720458\n",
      "1 :  0.7718397045390523\n",
      "2 :  0.7701547658068698\n",
      "0.5 :  0.77667312116357\n"
     ]
    }
   ],
   "source": [
    "for C in [0.75,1,2,0.5]:\n",
    "    lr_model = LogisticRegression(C = C)\n",
    "    lr_model.fit(X_train_bow,y_train_bow)\n",
    "    test_pred_lr_bow = lr_model.predict(X_test_bow)\n",
    "\n",
    "    #acc = 100 * np.sum(test_pred == y_test)/len(y_test)\n",
    "    print(C,\": \",f1_score(y_test_bow,test_pred_lr_bow,average='weighted') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7862537764350453"
      ]
     },
     "execution_count": 1144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y_test_bow == test_pred_lr_bow).sum()/len(y_test_bow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Logistic Regression Model - character n gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 727,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75 :  0.7515914006050404\n",
      "1 :  0.7530801481915396\n",
      "2 :  0.7519957127859939\n",
      "0.5 :  0.7514206118958465\n"
     ]
    }
   ],
   "source": [
    "for C in [0.75,1,2,0.5]:\n",
    "    lr_model = LogisticRegression(C = C)\n",
    "    lr_model.fit(X_train_char,y_train_char)\n",
    "    test_pred_lr_char = lr_model.predict(X_test_char)\n",
    "\n",
    "    #acc = 100 * np.sum(test_pred == y_test)/len(y_test)\n",
    "    print(C,\": \",f1_score(y_test_char,test_pred_lr_char,average='weighted') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 728,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7620845921450151"
      ]
     },
     "execution_count": 728,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y_test_char == test_pred_lr_char).sum()/len(y_test_char)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 740,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestClassifier(n_estimators = 50)\n",
    "rf_model.fit(X_train_bow,y_train_bow)\n",
    "test_pred_rf = rf_model.predict(X_test_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 741,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 :  0.7519213753831259\n",
      "Acc: 77.56797583081571\n"
     ]
    }
   ],
   "source": [
    "acc = 100 * np.sum(test_pred_rf == y_test_bow)/len(y_test_bow)\n",
    "print(\"F1 : \",f1_score(y_test_bow,test_pred_rf,average='weighted'))\n",
    "print(\"Acc:\", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 935,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arvra\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "xgb_model = XGBClassifier(n_estimators = 600, max_depth= 6,learning_rate = 0.3)\n",
    "xgb_model.fit(X_train_bow,y_train_bow)\n",
    "test_pred_xgb = xgb_model.predict(X_test_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 936,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 :  0.7653851532482638\n",
      "Acc: 77.56797583081571\n"
     ]
    }
   ],
   "source": [
    "acc = 100 * np.sum(test_pred_xgb == y_test_bow)/len(y_test_bow)\n",
    "print(\"F1 : \",f1_score(y_test,test_pred_xgb,average='weighted'))\n",
    "print(\"Acc:\", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 753,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame([test_pred_lr_bow,test_pred_lr_char,test_pred_rf,test_pred_xgb]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 764,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df['prediction'] = result_df.apply(lambda x: x.value_counts().index[0],axis= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 768,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78.20996978851964"
      ]
     },
     "execution_count": 768,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100 * np.sum(result_df['prediction'].values == y_test_bow)/len(y_test_bow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validating the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n = 20\n",
    "top_features = np.array(X_columns)[(-np.abs(lr_model.coef_)).argsort()[0][0:top_n]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hing!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ouch!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ws. .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fuck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fuck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>shit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>bitch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ews.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>shit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>liar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>hing.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>fool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ot we</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>liar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Ouch.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>is! 💥</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>e a m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>💥</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>awful</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0\n",
       "0   hing!\n",
       "1   Ouch!\n",
       "2   ws. .\n",
       "3    fuck\n",
       "4    fuck\n",
       "5    shit\n",
       "6   bitch\n",
       "7     ass\n",
       "8   ews. \n",
       "9    shit\n",
       "10   liar\n",
       "11  hing.\n",
       "12   fool\n",
       "13  ot we\n",
       "14   liar\n",
       "15  Ouch.\n",
       "16  is! 💥\n",
       "17  e a m\n",
       "18      💥\n",
       "19  awful"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(top_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking at some of the misclassified tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 773,
   "metadata": {},
   "outputs": [],
   "source": [
    "misclassified_tweets = train_df.iloc[(y_test_bow[(y_test_bow != result_df['prediction'].values)].index.values - 1).tolist(),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 775,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  398,  3162,  2071,  8001, 12048], dtype=int64)"
      ]
     },
     "execution_count": 775,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_bow[(y_test_bow != result_df['prediction'].values)].index.values[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 778,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Inputs with misclassification\n",
    "\n",
    "#X_test_misclassified = X_test_bow.toarray()[(y_test_bow != result_df['prediction'].values),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 777,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>subtask_a</th>\n",
       "      <th>subtask_b</th>\n",
       "      <th>subtask_c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>0</td>\n",
       "      <td>58548</td>\n",
       "      <td>@USER @USER Wonder if he apologized to Diamond...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>IND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3162</th>\n",
       "      <td>0</td>\n",
       "      <td>34571</td>\n",
       "      <td>\"an already-debunked viral hoax\"\" Tell me who ...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>IND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2071</th>\n",
       "      <td>0</td>\n",
       "      <td>49760</td>\n",
       "      <td>\"Black Female Democrats Call for Changes in Pa...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>GRP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8001</th>\n",
       "      <td>0</td>\n",
       "      <td>18083</td>\n",
       "      <td>@USER @USER @USER @USER Loved to hate MR in Bo...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>IND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12048</th>\n",
       "      <td>0</td>\n",
       "      <td>98896</td>\n",
       "      <td>@USER @USER Just saw it. Still vague though. H...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>IND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7132</th>\n",
       "      <td>0</td>\n",
       "      <td>90130</td>\n",
       "      <td>\"@USER @USER @USER @USER @USER @USER @USER @US...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>IND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7328</th>\n",
       "      <td>0</td>\n",
       "      <td>16191</td>\n",
       "      <td>@USER @USER @USER @USER shitt on Pitt - perfec...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>IND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13115</th>\n",
       "      <td>0</td>\n",
       "      <td>30186</td>\n",
       "      <td>@USER @USER @USER I think he is on crack!</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>IND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3356</th>\n",
       "      <td>0</td>\n",
       "      <td>55498</td>\n",
       "      <td>@USER @USER Tucker Carlson is not an idiot.  H...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>0</td>\n",
       "      <td>42133</td>\n",
       "      <td>@USER @USER @USER @USER @USER @USER You must b...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>GRP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0     id                                              tweet subtask_a  \\\n",
       "398    0  58548  @USER @USER Wonder if he apologized to Diamond...       OFF   \n",
       "3162   0  34571  \"an already-debunked viral hoax\"\" Tell me who ...       OFF   \n",
       "2071   0  49760  \"Black Female Democrats Call for Changes in Pa...       OFF   \n",
       "8001   0  18083  @USER @USER @USER @USER Loved to hate MR in Bo...       OFF   \n",
       "12048  0  98896  @USER @USER Just saw it. Still vague though. H...       OFF   \n",
       "7132   0  90130  \"@USER @USER @USER @USER @USER @USER @USER @US...       OFF   \n",
       "7328   0  16191  @USER @USER @USER @USER shitt on Pitt - perfec...       OFF   \n",
       "13115  0  30186          @USER @USER @USER I think he is on crack!       OFF   \n",
       "3356   0  55498  @USER @USER Tucker Carlson is not an idiot.  H...       NOT   \n",
       "314    0  42133  @USER @USER @USER @USER @USER @USER You must b...       OFF   \n",
       "\n",
       "      subtask_b subtask_c  \n",
       "398         TIN       IND  \n",
       "3162        TIN       IND  \n",
       "2071        TIN       GRP  \n",
       "8001        TIN       IND  \n",
       "12048       TIN       IND  \n",
       "7132        TIN       IND  \n",
       "7328        TIN       IND  \n",
       "13115       TIN       IND  \n",
       "3356       NULL      NULL  \n",
       "314         TIN       GRP  "
      ]
     },
     "execution_count": 777,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "misclassified_tweets.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>subtask_a</th>\n",
       "      <th>subtask_b</th>\n",
       "      <th>subtask_c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>0</td>\n",
       "      <td>68629</td>\n",
       "      <td>@USER Let the leftist democrats riot in the st...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>IND</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0     id                                              tweet subtask_a  \\\n",
       "148  0  68629  @USER Let the leftist democrats riot in the st...       OFF   \n",
       "\n",
       "    subtask_b subtask_c  \n",
       "148       TIN       IND  "
      ]
     },
     "execution_count": 607,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "misclassified_tweets.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 779,
   "metadata": {},
   "outputs": [],
   "source": [
    "misclassified_tweets.to_csv('misclassified_tweets_ensemble.csv',index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokens and Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.012921</th>\n",
       "      <td>disgrace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-0.042033</th>\n",
       "      <td>DISG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.004921</th>\n",
       "      <td>a DI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.419129</th>\n",
       "      <td>are</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.086794</th>\n",
       "      <td>you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-0.423991</th>\n",
       "      <td>@USER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.004921</th>\n",
       "      <td>DISGR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.033888</th>\n",
       "      <td>ER yo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.004921</th>\n",
       "      <td>GRACE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.004921</th>\n",
       "      <td>ISGRA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.043919</th>\n",
       "      <td>R you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.085148</th>\n",
       "      <td>SER y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.004921</th>\n",
       "      <td>SGRAC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.228845</th>\n",
       "      <td>USER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.004921</th>\n",
       "      <td>a DIS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.215317</th>\n",
       "      <td>are a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-0.061122</th>\n",
       "      <td>e a D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-0.481937</th>\n",
       "      <td>ou ar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.460558</th>\n",
       "      <td>re a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-0.473593</th>\n",
       "      <td>u are</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-0.144306</th>\n",
       "      <td>you a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.012921</th>\n",
       "      <td>disgrace</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0\n",
       " 0.012921  disgrace\n",
       "-0.042033      DISG\n",
       " 0.004921      a DI\n",
       " 0.419129      are \n",
       " 0.086794      you \n",
       "-0.423991     @USER\n",
       " 0.004921     DISGR\n",
       " 0.033888     ER yo\n",
       " 0.004921     GRACE\n",
       " 0.004921     ISGRA\n",
       " 0.043919     R you\n",
       " 0.085148     SER y\n",
       " 0.004921     SGRAC\n",
       " 0.228845     USER \n",
       " 0.004921     a DIS\n",
       " 0.215317     are a\n",
       "-0.061122     e a D\n",
       "-0.481937     ou ar\n",
       " 0.460558     re a \n",
       "-0.473593     u are\n",
       "-0.144306     you a\n",
       " 0.012921  disgrace"
      ]
     },
     "execution_count": 614,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "position_of_misclassified = 4\n",
    "\n",
    "\n",
    "non_zero_features = [pos for pos,each in enumerate(X_test_misclassified[position_of_misclassified]) if each > 0]\n",
    "\n",
    "tokens = np.array(X_columns)[non_zero_features]\n",
    "\n",
    "words = [X_columns.index(each) for each in tokens]\n",
    "score = [lr_model.coef_[0][each] for each in words]\n",
    "\n",
    "pd.DataFrame(tokens,score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 780,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OFF    133\n",
       "NOT    125\n",
       "Name: subtask_a, dtype: int64"
      ]
     },
     "execution_count": 780,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[train_df.tweet.str.contains('hate')].subtask_a.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 781,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>subtask_a</th>\n",
       "      <th>subtask_b</th>\n",
       "      <th>subtask_c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0</td>\n",
       "      <td>27645</td>\n",
       "      <td>\"@USER I do remember. :( But somehow centrist\"...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>0</td>\n",
       "      <td>28812</td>\n",
       "      <td>@USER This all I get 😢 damn these haters delet...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>GRP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>0</td>\n",
       "      <td>34317</td>\n",
       "      <td>\"@USER @USER @USER @USER @USER @USER @USER @US...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>IND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>0</td>\n",
       "      <td>42133</td>\n",
       "      <td>@USER @USER @USER @USER @USER @USER You must b...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>GRP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>0</td>\n",
       "      <td>30426</td>\n",
       "      <td>@USER @USER NOT A SNOWBALLS CHANCE IN HELL DIM...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>IND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524</th>\n",
       "      <td>0</td>\n",
       "      <td>85623</td>\n",
       "      <td>@USER Because he hates</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525</th>\n",
       "      <td>0</td>\n",
       "      <td>81520</td>\n",
       "      <td>@USER The hypocrisy of the #NEverTrump movemen...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574</th>\n",
       "      <td>0</td>\n",
       "      <td>93516</td>\n",
       "      <td>@USER Get the hell out of my country that u ha...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625</th>\n",
       "      <td>0</td>\n",
       "      <td>14239</td>\n",
       "      <td>@USER @USER Such delusional liberals..! So twi...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>OTH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>642</th>\n",
       "      <td>0</td>\n",
       "      <td>83576</td>\n",
       "      <td>@USER @USER @USER We have a stupid problem. Co...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>UNT</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>662</th>\n",
       "      <td>0</td>\n",
       "      <td>39492</td>\n",
       "      <td>@USER @USER Well he's a liberal so that explai...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>GRP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718</th>\n",
       "      <td>0</td>\n",
       "      <td>77575</td>\n",
       "      <td>@USER @USER We've had millions of people march...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>0</td>\n",
       "      <td>24797</td>\n",
       "      <td>@USER @USER @USER @USER @USER This hand signal...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>UNT</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760</th>\n",
       "      <td>0</td>\n",
       "      <td>97760</td>\n",
       "      <td>@USER When are the Republicans going to learn ...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>OTH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>770</th>\n",
       "      <td>0</td>\n",
       "      <td>87737</td>\n",
       "      <td>@USER Just one more proof that the dnc hates t...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>GRP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>840</th>\n",
       "      <td>0</td>\n",
       "      <td>65852</td>\n",
       "      <td>@USER @USER @USER @USER @USER Sis she is. And ...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>0</td>\n",
       "      <td>73118</td>\n",
       "      <td>@USER @USER @USER @USER @USER I did not admit ...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>GRP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>935</th>\n",
       "      <td>0</td>\n",
       "      <td>69671</td>\n",
       "      <td>@USER @USER @USER @USER @USER @USER @USER @USE...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>953</th>\n",
       "      <td>0</td>\n",
       "      <td>82680</td>\n",
       "      <td>@USER Funny how liberals and liberal stars hat...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1051</th>\n",
       "      <td>0</td>\n",
       "      <td>82977</td>\n",
       "      <td>@USER @USER I stand corrected! Guess the only ...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1074</th>\n",
       "      <td>0</td>\n",
       "      <td>42234</td>\n",
       "      <td>@USER @USER @USER @USER @USER There is absolut...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>GRP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1161</th>\n",
       "      <td>0</td>\n",
       "      <td>44744</td>\n",
       "      <td>\"@USER @USER @USER @USER And while yes, hate g...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1201</th>\n",
       "      <td>0</td>\n",
       "      <td>75566</td>\n",
       "      <td>@USER @USER @USER Thanks for the resistance bo...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1262</th>\n",
       "      <td>0</td>\n",
       "      <td>86725</td>\n",
       "      <td>@USER @USER @USER Don't know who he is and don...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>IND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1379</th>\n",
       "      <td>0</td>\n",
       "      <td>11812</td>\n",
       "      <td>@USER @USER I had the good fortune of having h...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1495</th>\n",
       "      <td>0</td>\n",
       "      <td>62830</td>\n",
       "      <td>@USER @USER What? I have no clue what you are ...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1626</th>\n",
       "      <td>0</td>\n",
       "      <td>44648</td>\n",
       "      <td>@USER @USER @USER @USER @USER @USER @USER What...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1690</th>\n",
       "      <td>0</td>\n",
       "      <td>44550</td>\n",
       "      <td>@USER @USER middle class voted &amp;amp; continue ...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1795</th>\n",
       "      <td>0</td>\n",
       "      <td>10540</td>\n",
       "      <td>@USER Blaming Trump for the hurricane is showi...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>IND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1832</th>\n",
       "      <td>0</td>\n",
       "      <td>43641</td>\n",
       "      <td>\"23:70 Or do they say, He is possessed\"\"? Nay,...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>GRP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12109</th>\n",
       "      <td>0</td>\n",
       "      <td>71890</td>\n",
       "      <td>@USER @USER @USER Thanks that sums it up nicel...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12201</th>\n",
       "      <td>0</td>\n",
       "      <td>71775</td>\n",
       "      <td>@USER @USER .  The #MeToo has been ruined by h...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>GRP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12258</th>\n",
       "      <td>0</td>\n",
       "      <td>43528</td>\n",
       "      <td>@USER @USER @USER @USER @USER @USER @USER That...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>GRP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12262</th>\n",
       "      <td>0</td>\n",
       "      <td>66351</td>\n",
       "      <td>@USER The hate really takes a toll on these pe...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>GRP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12313</th>\n",
       "      <td>0</td>\n",
       "      <td>77054</td>\n",
       "      <td>@USER @USER let’s throw up some added bureaucr...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12315</th>\n",
       "      <td>0</td>\n",
       "      <td>88415</td>\n",
       "      <td>@USER Frankly I hate that argument. Gun contro...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>UNT</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12326</th>\n",
       "      <td>0</td>\n",
       "      <td>81874</td>\n",
       "      <td>@USER Because liberals hate America and cant s...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12331</th>\n",
       "      <td>0</td>\n",
       "      <td>84107</td>\n",
       "      <td>I hate the Democrats but they do Fight like H3...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>GRP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12349</th>\n",
       "      <td>0</td>\n",
       "      <td>44485</td>\n",
       "      <td>@USER Clarence Thomas was branded by Democrats...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12374</th>\n",
       "      <td>0</td>\n",
       "      <td>68169</td>\n",
       "      <td>\"@USER @USER Yes, READ it again. They use a te...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12407</th>\n",
       "      <td>0</td>\n",
       "      <td>30132</td>\n",
       "      <td>\"@USER @USER @USER @USER @USER My experience i...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12481</th>\n",
       "      <td>0</td>\n",
       "      <td>20384</td>\n",
       "      <td>@USER EVERY TIME! i hate it its the most horri...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>IND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12522</th>\n",
       "      <td>0</td>\n",
       "      <td>84702</td>\n",
       "      <td>@USER Hopefully it is joking.  I hate boycotti...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>IND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12588</th>\n",
       "      <td>0</td>\n",
       "      <td>61760</td>\n",
       "      <td>@USER @USER Do you hate him that much. He is O...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>IND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12744</th>\n",
       "      <td>0</td>\n",
       "      <td>78758</td>\n",
       "      <td>@USER @USER I hate 7 year old faggot Logan fan...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>IND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12747</th>\n",
       "      <td>0</td>\n",
       "      <td>61580</td>\n",
       "      <td>@USER A liberal anarchist coup d'etat gang run...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12798</th>\n",
       "      <td>0</td>\n",
       "      <td>92648</td>\n",
       "      <td>@USER @USER @USER And his son the ANTIFA maske...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12823</th>\n",
       "      <td>0</td>\n",
       "      <td>31264</td>\n",
       "      <td>@USER This isn’t about gun control anymore thi...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12842</th>\n",
       "      <td>0</td>\n",
       "      <td>59861</td>\n",
       "      <td>@USER I thought the left hated guns? And gun v...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>IND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12860</th>\n",
       "      <td>0</td>\n",
       "      <td>12840</td>\n",
       "      <td>#KKK &amp;amp; Gun Control are traditions of @USER...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>OTH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12903</th>\n",
       "      <td>0</td>\n",
       "      <td>11805</td>\n",
       "      <td>@USER @USER @USER Lindsey will never sink as l...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>IND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12937</th>\n",
       "      <td>0</td>\n",
       "      <td>10144</td>\n",
       "      <td>@USER @USER I agree..but they are still conser...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12959</th>\n",
       "      <td>0</td>\n",
       "      <td>76511</td>\n",
       "      <td>@USER Hate is hate no matter what side of the ...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12985</th>\n",
       "      <td>0</td>\n",
       "      <td>86737</td>\n",
       "      <td>@USER The FBi has made it so that @USER cannot...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12992</th>\n",
       "      <td>0</td>\n",
       "      <td>91045</td>\n",
       "      <td>@USER @USER @USER @USER Apparently bald men ha...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13000</th>\n",
       "      <td>0</td>\n",
       "      <td>10742</td>\n",
       "      <td>@USER please don’t tell me your going left? Us...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13049</th>\n",
       "      <td>0</td>\n",
       "      <td>88584</td>\n",
       "      <td>\"... the liberal's ... tendency to deal with o...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13152</th>\n",
       "      <td>0</td>\n",
       "      <td>77459</td>\n",
       "      <td>@USER It’s just people who say they hate ident...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>GRP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13164</th>\n",
       "      <td>0</td>\n",
       "      <td>84367</td>\n",
       "      <td>@USER @USER No I have no relationship with him...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>IND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13178</th>\n",
       "      <td>0</td>\n",
       "      <td>43323</td>\n",
       "      <td>Americans make great clients! But so many appr...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>258 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0     id                                              tweet subtask_a  \\\n",
       "74     0  27645  \"@USER I do remember. :( But somehow centrist\"...       NOT   \n",
       "137    0  28812  @USER This all I get 😢 damn these haters delet...       OFF   \n",
       "234    0  34317  \"@USER @USER @USER @USER @USER @USER @USER @US...       OFF   \n",
       "314    0  42133  @USER @USER @USER @USER @USER @USER You must b...       OFF   \n",
       "486    0  30426  @USER @USER NOT A SNOWBALLS CHANCE IN HELL DIM...       OFF   \n",
       "524    0  85623                             @USER Because he hates       NOT   \n",
       "525    0  81520  @USER The hypocrisy of the #NEverTrump movemen...       NOT   \n",
       "574    0  93516  @USER Get the hell out of my country that u ha...       NOT   \n",
       "625    0  14239  @USER @USER Such delusional liberals..! So twi...       OFF   \n",
       "642    0  83576  @USER @USER @USER We have a stupid problem. Co...       OFF   \n",
       "662    0  39492  @USER @USER Well he's a liberal so that explai...       OFF   \n",
       "718    0  77575  @USER @USER We've had millions of people march...       NOT   \n",
       "757    0  24797  @USER @USER @USER @USER @USER This hand signal...       OFF   \n",
       "760    0  97760  @USER When are the Republicans going to learn ...       OFF   \n",
       "770    0  87737  @USER Just one more proof that the dnc hates t...       OFF   \n",
       "840    0  65852  @USER @USER @USER @USER @USER Sis she is. And ...       NOT   \n",
       "884    0  73118  @USER @USER @USER @USER @USER I did not admit ...       OFF   \n",
       "935    0  69671  @USER @USER @USER @USER @USER @USER @USER @USE...       NOT   \n",
       "953    0  82680  @USER Funny how liberals and liberal stars hat...       NOT   \n",
       "1051   0  82977  @USER @USER I stand corrected! Guess the only ...       NOT   \n",
       "1074   0  42234  @USER @USER @USER @USER @USER There is absolut...       OFF   \n",
       "1161   0  44744  \"@USER @USER @USER @USER And while yes, hate g...       NOT   \n",
       "1201   0  75566  @USER @USER @USER Thanks for the resistance bo...       NOT   \n",
       "1262   0  86725  @USER @USER @USER Don't know who he is and don...       OFF   \n",
       "1379   0  11812  @USER @USER I had the good fortune of having h...       NOT   \n",
       "1495   0  62830  @USER @USER What? I have no clue what you are ...       NOT   \n",
       "1626   0  44648  @USER @USER @USER @USER @USER @USER @USER What...       NOT   \n",
       "1690   0  44550  @USER @USER middle class voted &amp; continue ...       NOT   \n",
       "1795   0  10540  @USER Blaming Trump for the hurricane is showi...       OFF   \n",
       "1832   0  43641  \"23:70 Or do they say, He is possessed\"\"? Nay,...       OFF   \n",
       "...   ..    ...                                                ...       ...   \n",
       "12109  0  71890  @USER @USER @USER Thanks that sums it up nicel...       NOT   \n",
       "12201  0  71775  @USER @USER .  The #MeToo has been ruined by h...       OFF   \n",
       "12258  0  43528  @USER @USER @USER @USER @USER @USER @USER That...       OFF   \n",
       "12262  0  66351  @USER The hate really takes a toll on these pe...       OFF   \n",
       "12313  0  77054  @USER @USER let’s throw up some added bureaucr...       NOT   \n",
       "12315  0  88415  @USER Frankly I hate that argument. Gun contro...       OFF   \n",
       "12326  0  81874  @USER Because liberals hate America and cant s...       NOT   \n",
       "12331  0  84107  I hate the Democrats but they do Fight like H3...       OFF   \n",
       "12349  0  44485  @USER Clarence Thomas was branded by Democrats...       NOT   \n",
       "12374  0  68169  \"@USER @USER Yes, READ it again. They use a te...       NOT   \n",
       "12407  0  30132  \"@USER @USER @USER @USER @USER My experience i...       NOT   \n",
       "12481  0  20384  @USER EVERY TIME! i hate it its the most horri...       OFF   \n",
       "12522  0  84702  @USER Hopefully it is joking.  I hate boycotti...       OFF   \n",
       "12588  0  61760  @USER @USER Do you hate him that much. He is O...       OFF   \n",
       "12744  0  78758  @USER @USER I hate 7 year old faggot Logan fan...       OFF   \n",
       "12747  0  61580  @USER A liberal anarchist coup d'etat gang run...       NOT   \n",
       "12798  0  92648  @USER @USER @USER And his son the ANTIFA maske...       NOT   \n",
       "12823  0  31264  @USER This isn’t about gun control anymore thi...       NOT   \n",
       "12842  0  59861  @USER I thought the left hated guns? And gun v...       OFF   \n",
       "12860  0  12840  #KKK &amp; Gun Control are traditions of @USER...       OFF   \n",
       "12903  0  11805  @USER @USER @USER Lindsey will never sink as l...       OFF   \n",
       "12937  0  10144  @USER @USER I agree..but they are still conser...       NOT   \n",
       "12959  0  76511  @USER Hate is hate no matter what side of the ...       NOT   \n",
       "12985  0  86737  @USER The FBi has made it so that @USER cannot...       NOT   \n",
       "12992  0  91045  @USER @USER @USER @USER Apparently bald men ha...       NOT   \n",
       "13000  0  10742  @USER please don’t tell me your going left? Us...       NOT   \n",
       "13049  0  88584  \"... the liberal's ... tendency to deal with o...       NOT   \n",
       "13152  0  77459  @USER It’s just people who say they hate ident...       OFF   \n",
       "13164  0  84367  @USER @USER No I have no relationship with him...       OFF   \n",
       "13178  0  43323  Americans make great clients! But so many appr...       NOT   \n",
       "\n",
       "      subtask_b subtask_c  \n",
       "74         NULL      NULL  \n",
       "137         TIN       GRP  \n",
       "234         TIN       IND  \n",
       "314         TIN       GRP  \n",
       "486         TIN       IND  \n",
       "524        NULL      NULL  \n",
       "525        NULL      NULL  \n",
       "574        NULL      NULL  \n",
       "625         TIN       OTH  \n",
       "642         UNT      NULL  \n",
       "662         TIN       GRP  \n",
       "718        NULL      NULL  \n",
       "757         UNT      NULL  \n",
       "760         TIN       OTH  \n",
       "770         TIN       GRP  \n",
       "840        NULL      NULL  \n",
       "884         TIN       GRP  \n",
       "935        NULL      NULL  \n",
       "953        NULL      NULL  \n",
       "1051       NULL      NULL  \n",
       "1074        TIN       GRP  \n",
       "1161       NULL      NULL  \n",
       "1201       NULL      NULL  \n",
       "1262        TIN       IND  \n",
       "1379       NULL      NULL  \n",
       "1495       NULL      NULL  \n",
       "1626       NULL      NULL  \n",
       "1690       NULL      NULL  \n",
       "1795        TIN       IND  \n",
       "1832        TIN       GRP  \n",
       "...         ...       ...  \n",
       "12109      NULL      NULL  \n",
       "12201       TIN       GRP  \n",
       "12258       TIN       GRP  \n",
       "12262       TIN       GRP  \n",
       "12313      NULL      NULL  \n",
       "12315       UNT      NULL  \n",
       "12326      NULL      NULL  \n",
       "12331       TIN       GRP  \n",
       "12349      NULL      NULL  \n",
       "12374      NULL      NULL  \n",
       "12407      NULL      NULL  \n",
       "12481       TIN       IND  \n",
       "12522       TIN       IND  \n",
       "12588       TIN       IND  \n",
       "12744       TIN       IND  \n",
       "12747      NULL      NULL  \n",
       "12798      NULL      NULL  \n",
       "12823      NULL      NULL  \n",
       "12842       TIN       IND  \n",
       "12860       TIN       OTH  \n",
       "12903       TIN       IND  \n",
       "12937      NULL      NULL  \n",
       "12959      NULL      NULL  \n",
       "12985      NULL      NULL  \n",
       "12992      NULL      NULL  \n",
       "13000      NULL      NULL  \n",
       "13049      NULL      NULL  \n",
       "13152       TIN       GRP  \n",
       "13164       TIN       IND  \n",
       "13178      NULL      NULL  \n",
       "\n",
       "[258 rows x 6 columns]"
      ]
     },
     "execution_count": 781,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[train_df.tweet.str.contains('hate')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 706,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000 :  72.84743202416918\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1629,  141],\n",
       "       [ 578,  300]], dtype=int64)"
      ]
     },
     "execution_count": 706,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_model = LogisticRegression(C = 2500)\n",
    "lr_model.fit(X_train,y_train)\n",
    "test_pred = lr_model.predict(X_test)\n",
    "\n",
    "print(C,\": \",100 * np.sum(test_pred == y_test)/len(y_test))\n",
    "confusion_matrix(y_test,test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 707,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6984123845797418"
      ]
     },
     "execution_count": 707,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_model = RandomForestClassifier()\n",
    "rf_model.fit(X_train,y_train)\n",
    "\n",
    "test_pred = lr_model.predict(X_test)\n",
    "f1_score(y_test,test_pred,average='weighted') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autocorrect import spell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello'"
      ]
     },
     "execution_count": 588,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spell('helooo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet = '@USER ðŸ‘ŒðŸ» Iâ€™ve never seen anyone talk like that on Twitter before and Iâ€™ve seen some really messed up shit'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'he'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spell('he!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello'"
      ]
     },
     "execution_count": 602,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
